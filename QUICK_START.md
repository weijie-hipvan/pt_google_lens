# âš¡ Quick Start Guide
## Get Started with AI Agent

---

## ğŸ¯ OVERVIEW

This project consists of **3 documentation files**:

| File | Purpose |
|------|---------|
| `IMPLEMENTATION_PLAN.md` | Detailed technical spec, architecture, code samples |
| `AI_AGENT_PROMPTS.md` | Prompt templates to copy-paste for AI agent |
| `QUICK_START.md` | Quick start guide (this file) |

---

## ğŸ—ï¸ ARCHITECTURE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FRONTEND           â”‚     â”‚   BACKEND            â”‚
â”‚   (Next.js + React)  â”‚â”€â”€â”€â”€â–¶â”‚   (Rails API)        â”‚
â”‚   Port: 3000         â”‚     â”‚   Port: 3001         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚   Google Vision API   â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ START IMPLEMENTATION

### Step 1: Setup Backend - Rails API (10 min)

Copy this prompt and paste into AI agent:

```
Create a Rails 7 API-only application for AI object detection.
Project name: ai-tagging-api

Add gems: rack-cors, faraday, dotenv-rails

Create services for Google Vision API integration with adapter pattern.
Create POST /api/v1/detections endpoint.
Configure CORS for frontend at localhost:3000.

See IMPLEMENTATION_PLAN.md for detailed code samples.
```

---

### Step 2: Setup Frontend - Next.js (5 min)

```
Create a Next.js 14 project with TypeScript and Tailwind.
Project name: ai-tagging-ui

Install: konva, react-konva, zustand, uuid, axios

Create TypeScript types for AI detection system.
Create API client to call Rails backend.

See IMPLEMENTATION_PLAN.md Task 1.9-1.12.
```

---

### Step 3: Core Backend Services (15 min)

**Prompt 1 - Adapters:**
```
Create AI adapter classes in app/services/ai/:
- base_adapter.rb - abstract interface
- google_vision_adapter.rb - Google Cloud Vision implementation
- detection_service.rb - orchestration layer

See IMPLEMENTATION_PLAN.md Tasks 1.4-1.6 for full code.
```

**Prompt 2 - Controller:**
```
Create the detections controller at app/controllers/api/v1/detections_controller.rb
Handle POST with image and options params.
Return normalized JSON response.

See IMPLEMENTATION_PLAN.md Task 1.7.
```

---

### Step 4: Zustand Store (5 min)

```
Create store/taggingStore.ts with Zustand.
State: imageUrl, imageBase64, imageDimensions, objects, isLoading, error, selectedObjectId
Actions: setImage, clearImage, setObjects, acceptObject, rejectObject, acceptAll, rejectAll

See IMPLEMENTATION_PLAN.md Task 2.1.
```

---

### Step 5: UI Components (20 min)

**Create in order:**

1. `components/ImageUploader.tsx` - Drag & drop upload
2. `components/ConfidenceBadge.tsx` - Color-coded confidence (ğŸŸ¢ğŸŸ¡ğŸ”´)
3. `components/ObjectList.tsx` - Sidebar with detected objects
4. `components/CanvasViewer.tsx` - React Konva canvas with bounding boxes
5. `components/ActionBar.tsx` - Action buttons

See detailed prompts in `AI_AGENT_PROMPTS.md` Phase 2.

---

### Step 6: Integration (10 min)

```
Update app/page.tsx to integrate all components:
- Header with title
- ActionBar
- Conditional: ImageUploader or CanvasViewer
- ObjectList sidebar
- ExportModal
- Handle API calls and state management
```

---

### Step 7: Export & Polish (10 min)

```
1. Create components/ExportModal.tsx - Modal to export JSON
2. Add loading states and error handling
3. Polish UI: colors, spacing, transitions
```

---

## ğŸ“‹ TASK CHECKLIST

Mark as complete when done:

### Phase 1: Foundation
**Backend (Rails)**
- [ ] Create Rails API project
- [ ] Configure CORS
- [ ] Set up environment variables
- [ ] Create BaseAdapter class
- [ ] Implement GoogleVisionAdapter
- [ ] Create DetectionService
- [ ] Create DetectionsController
- [ ] Configure routes

**Frontend (Next.js)**
- [ ] Create Next.js project
- [ ] Install dependencies
- [ ] Create TypeScript types
- [ ] Create API client

### Phase 2: Core UI
- [ ] Create Zustand store
- [ ] Create ImageUploader component
- [ ] Create ConfidenceBadge component
- [ ] Create ObjectList component
- [ ] Create CanvasViewer component
- [ ] Create ActionBar component

### Phase 3: Integration
- [ ] Create ExportModal component
- [ ] Integrate main page
- [ ] Add error handling
- [ ] Polish UI styling

### Phase 4: Deploy
- [ ] Deploy Rails API (Render/Railway)
- [ ] Deploy Next.js frontend (Vercel)
- [ ] Test full flow
- [ ] Prepare demo

---

## ğŸ”‘ ENVIRONMENT SETUP

### Backend (.env)
```env
GOOGLE_CLOUD_API_KEY=your_api_key_here
FRONTEND_URL=http://localhost:3000
```

### Frontend (.env.local)
```env
NEXT_PUBLIC_API_URL=http://localhost:3001
```

### Get Google Cloud API Key:
1. Go to [Google Cloud Console](https://console.cloud.google.com)
2. Enable "Cloud Vision API"
3. Create API key
4. Add to .env file

---

## ğŸ–¥ï¸ RUN LOCALLY

**Terminal 1 - Backend:**
```bash
cd ai-tagging-api
bundle install
rails s -p 3001
```

**Terminal 2 - Frontend:**
```bash
cd ai-tagging-ui
npm install
npm run dev
```

**Open:** http://localhost:3000

---

## ğŸ’¡ TIPS

1. **Test early**: After completing API route, test with curl before building UI

2. **Mock data**: Prepare mock responses to test UI while API is being built

3. **Incremental commits**: Commit after each component is complete

4. **Debug freely**: Console.log liberally, clean up later

---

## ğŸ¬ DEMO FLOW

Flow for demonstration:

```
1. Open app â†’ See upload zone
2. Drag image â†’ Preview shows
3. Click "Boost with AI âœ¨" â†’ Loading...
4. Bounding boxes appear â†’ Wow!
5. Click box â†’ Highlight + select in list
6. Accept/Reject objects
7. Click "Export" â†’ JSON modal
8. Copy/Download â†’ Done!
```

---

## ğŸ†˜ STUCK?

If you encounter issues, use debug prompts in `AI_AGENT_PROMPTS.md`:
- "Debug: API Connection Issues"
- "Debug: Google Vision API Errors"
- "Debug: Canvas Not Rendering"

Or ask AI agent with specific context:
```
I'm implementing [component/feature].
Error: [error message]
Current code: [paste code]
What needs to be fixed?
```

---

## ğŸ“ FINAL PROJECT STRUCTURE

```
/ai-tagging-api (Rails)
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ controllers/api/v1/detections_controller.rb
â”‚   â””â”€â”€ services/ai/
â”‚       â”œâ”€â”€ base_adapter.rb
â”‚       â”œâ”€â”€ google_vision_adapter.rb
â”‚       â””â”€â”€ detection_service.rb
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ routes.rb
â”‚   â””â”€â”€ initializers/cors.rb
â””â”€â”€ .env

/ai-tagging-ui (Next.js)
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ page.tsx
â”‚   â”œâ”€â”€ layout.tsx
â”‚   â””â”€â”€ globals.css
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ImageUploader.tsx
â”‚   â”œâ”€â”€ CanvasViewer.tsx
â”‚   â”œâ”€â”€ ObjectList.tsx
â”‚   â”œâ”€â”€ ActionBar.tsx
â”‚   â”œâ”€â”€ ConfidenceBadge.tsx
â”‚   â””â”€â”€ ExportModal.tsx
â”œâ”€â”€ lib/api.ts
â”œâ”€â”€ store/taggingStore.ts
â”œâ”€â”€ types/ai.ts
â””â”€â”€ .env.local
```

---

**Good luck with the hackathon! ğŸš€**
